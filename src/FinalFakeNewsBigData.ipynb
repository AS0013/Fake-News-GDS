{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt') ----> udkommenter denne linje, hvis du ikke har nltk installeret\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('995,000_rows.csv',dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanText(text):\n",
    "    # lower case\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "\n",
    "    # should not contain multiple spaces, tabs or newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    #  january 18, 2018. jan 18, 2018. 2018-01-18\n",
    "    date_pattern = r'\\b(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\\s+\\d{1,2}(?:,\\s+|\\s+)\\d{4}\\b|\\b\\d{4}-\\d{2}-\\d{2}\\b'\n",
    "\n",
    "    text = re.sub(date_pattern, '<DATE>', text)\n",
    "    # nov. 5\n",
    "    date_pattern2 = r'\\b(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\\.\\s+\\d{1,2}\\b'\n",
    "    text = re.sub(date_pattern2, '<DATE>', text)\n",
    "\n",
    "    # replace numbers with <NUM>\n",
    "    text = re.sub(r'\\d+', '<NUM>', text)\n",
    "\n",
    "    # replace urls with <URL>\n",
    "    text = re.sub(r'(http|https)://[^\\s]*', '<URL>', text)\n",
    "\n",
    "    # replace emails with <EMAIL>\n",
    "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,4}\\b', '<EMAIL>', text)\n",
    "\n",
    "\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial exploratory data analysis\n",
    "\n",
    "# see how many domains are in the dataset\n",
    "domains = data['domain'].value_counts()\n",
    "# print(domains)\n",
    "\n",
    "# see if there are any missing values in ['domain']\n",
    "missing_domain = data['domain'].isnull().sum()\n",
    "# print('Missing domain:', missing_domain)\n",
    "\n",
    "# see if how many domains have 'reliable' as their type\n",
    "reliable_domains = data[data['type'] == 'reliable']['domain'].value_counts()\n",
    "# print(reliable_domains)\n",
    "\n",
    "# see for each domain how many reliable and fake news articles they have\n",
    "reliable_fake = data.groupby(['domain', 'type']).size()\n",
    "print(reliable_fake)\n",
    "\n",
    "\n",
    "# see how many diferent types there are and print them\n",
    "types = data['type'].value_counts()\n",
    "print(types)\n",
    "\n",
    "\n",
    "# plot 10 domains with the most articles with their type\n",
    "\n",
    "reliable_fake = reliable_fake.unstack()\n",
    "# fillna(0) replaces all NaN values with 0\n",
    "reliable_fake = reliable_fake.fillna(0)\n",
    "reliable_fake['total'] = reliable_fake['reliable'] + reliable_fake['fake'] + reliable_fake['satire'] + reliable_fake['bias'] + reliable_fake['conspiracy'] + reliable_fake['hate']+ reliable_fake['junksci'] + reliable_fake['clickbait'] + reliable_fake['unreliable'] + reliable_fake['political'] + reliable_fake['rumor'] + reliable_fake['unknown'] \n",
    "reliable_fake = reliable_fake.sort_values(by='total', ascending=False)\n",
    "reliable_fake = reliable_fake.head(10)\n",
    "reliable_fake = reliable_fake.drop(columns='total')\n",
    "reliable_fake.plot(kind='bar', stacked=True, figsize=(12, 7))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print what percent of the articles are of type reliable\n",
    "reliable_percent = types['reliable'] / data.shape[0] * 100\n",
    "print('Reliable percent:', reliable_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing missing values, classifying the data,\n",
    "\n",
    "data = data.dropna(subset=['type', 'content'])\n",
    "\n",
    "# replace 'political' and 'clickbait' with 'reliable'\n",
    "data['type'] = data['type'].replace(['political', 'clickbait'], 'reliable')\n",
    "\n",
    "#  remove all the other types of news except 'reliable' and 'fake'\n",
    "data = data[data['type'].isin(['reliable', 'fake'])]\n",
    "\n",
    "\n",
    "print('Total rows after removing missing values:', data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the text\n",
    "data['content'] = data['content'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "data['tokens'] = data['content'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords and stemming the tokens\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def process_tokens(tokens):\n",
    "    # remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    return stemmed_tokens\n",
    "\n",
    "data['processed_tokens'] = data['tokens'].apply(process_tokens).apply(lambda x: ' '.join(x))\n",
    "# data['processed_tokens'] = data['content'].apply(lambda x:' '.join([stemmer.stem(word) for word in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after removing missing values: 691768\n",
      "type\n",
      "reliable    440493\n",
      "fake        251275\n",
      "Name: count, dtype: int64\n",
      "Reliable percent: 63.6764059626927\n"
     ]
    }
   ],
   "source": [
    "# reading the other cleaned data\n",
    "cleaned_stemmed = pd.read_csv('995,000_cleaned_stemmed2.csv', dtype=str)\n",
    "\n",
    "cleaned_stemmed = cleaned_stemmed.dropna(subset=['type', 'content'])\n",
    "\n",
    "# replace 'political' and 'clickbait' with 'reliable'\n",
    "cleaned_stemmed['type'] = cleaned_stemmed['type'].replace(['political', 'clickbait'], 'reliable')\n",
    "\n",
    "# replace 'bias' and 'satite' with 'fake'\n",
    "cleaned_stemmed['type'] = cleaned_stemmed['type'].replace(['bias', 'satire'], 'fake')\n",
    "#  remove all the other types of news except 'reliable' and 'fake'\n",
    "cleaned_stemmed = cleaned_stemmed[cleaned_stemmed['type'].isin(['reliable', 'fake'])]\n",
    "\n",
    "print('Total rows after removing missing values:', cleaned_stemmed.shape[0]) \n",
    "\n",
    "print(cleaned_stemmed['type'].value_counts())\n",
    "\n",
    "# percent reliable\n",
    "reliable_percent = cleaned_stemmed['type'].value_counts()['reliable'] / cleaned_stemmed.shape[0] * 100\n",
    "print('Reliable percent:', reliable_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using either CountVectorizer or TfidfVectorizer to convert the text data into numerical data\n",
    "CountVectorizer = CountVectorizer()\n",
    "tfidvec = TfidfVectorizer(stop_words='english',max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "\n",
    "# X = CountVectorizer.fit_transform(cleaned_stemmed['content'])\n",
    "X = tfidvec.fit_transform(cleaned_stemmed['content'])\n",
    "# X = CountVectorizer.fit_transform(data['processed_tokens'])\n",
    "\n",
    "\n",
    "X_train, X_test_1, y_train, y_test_1  = train_test_split(X, cleaned_stemmed['type'], test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_1, y_test_1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the liad tsv file\n",
    "liar_data_test = pd.read_csv('LIARDATASET/train.tsv', sep='\\t', header=None)\n",
    "\n",
    "# only keep the 'true' and 'false' labels\n",
    "liar_data_test = liar_data_test[liar_data_test[1].isin(['true', 'false'])]\n",
    "\n",
    "X_liar = liar_data_test[2]\n",
    "y_liar = liar_data_test[1]\n",
    "\n",
    "# change the labels to 'reliable' and 'fake'\n",
    "y_liar = y_liar.replace('true', 'reliable')\n",
    "y_liar = y_liar.replace('false', 'fake')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "\n",
    "scale = StandardScaler(with_mean=False)\n",
    "\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training baseline model: logistic regression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=3500, random_state=42)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0      1                                                  2   \\\n",
      "0    2635.json  false  Says the Annies List political group supports ...   \n",
      "3    1123.json  false  Health care reform legislation is likely to ma...   \n",
      "5   12465.json   true  The Chicago Bears have had more starting quart...   \n",
      "12   5947.json  false  When Mitt Romney was governor of Massachusetts...   \n",
      "16    620.json   true  McCain opposed a requirement that the governme...   \n",
      "\n",
      "                      3             4                           5   \\\n",
      "0               abortion  dwayne-bohac        State representative   \n",
      "3            health-care  blog-posting                         NaN   \n",
      "5              education     robin-vos  Wisconsin Assembly speaker   \n",
      "12  history,state-budget   mitt-romney             Former governor   \n",
      "16        federal-budget  barack-obama                   President   \n",
      "\n",
      "               6           7     8     9      10     11    12  \\\n",
      "0           Texas  republican   0.0   1.0    0.0    0.0   0.0   \n",
      "3             NaN        none   7.0  19.0    3.0    5.0  44.0   \n",
      "5       Wisconsin  republican   0.0   3.0    2.0    5.0   1.0   \n",
      "12  Massachusetts  republican  34.0  32.0   58.0   33.0  19.0   \n",
      "16       Illinois    democrat  70.0  71.0  160.0  163.0   9.0   \n",
      "\n",
      "                            13  \n",
      "0                     a mailer  \n",
      "3               a news release  \n",
      "5    a an online opinion-piece  \n",
      "12  an interview with CBN News  \n",
      "16                  a radio ad  \n"
     ]
    }
   ],
   "source": [
    "# predicting: testing set\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training svm model:\n",
    "clf = svm.LinearSVC(max_iter=5000, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the svm model\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training random forest model\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicitng with the random forest model\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training naive bayes model\n",
    "\n",
    "naive = MultinomialNB()\n",
    "naive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the naive bayes model\n",
    "y_pred = naive.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training neural network model\n",
    "\n",
    "mlp = MLPClassifier(random_state=42, max_iter=500, hidden_layer_sizes=(128,64))\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the neural network model\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
